// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO2

package org.apache.mesos.v1.maintenance

import org.apache.mesos.v1.allocator.InverseOfferStatus
import org.apache.mesos.v1.{allocator, maintenance}

/** *
  * Represents the maintenance status of each machine in the cluster.
  * The lists correspond to the `MachineInfo.Mode` enumeration.
  */
@SerialVersionUID(0L)
final case class ClusterStatus(
                                drainingMachines: _root_.scala.collection.Seq[ClusterStatus.DrainingMachine] = _root_.scala.collection.Seq.empty,
                                downMachines: _root_.scala.collection.Seq[org.apache.mesos.v1.mesos.MachineID] = _root_.scala.collection.Seq.empty
    ) extends com.trueaccord.scalapb.GeneratedMessage with com.trueaccord.scalapb.Message[ClusterStatus] with com.trueaccord.lenses.Updatable[ClusterStatus] {
    @transient
    private[this] var __serializedSizeCachedValue: Int = 0
    private[this] def __computeSerializedValue(): Int = {
      var __size = 0
      drainingMachines.foreach(drainingMachines => __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(drainingMachines.serializedSize) + drainingMachines.serializedSize)
      downMachines.foreach(downMachines => __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(downMachines.serializedSize) + downMachines.serializedSize)
      __size
    }
    final override def serializedSize: Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): Unit = {
      drainingMachines.foreach { __v =>
        _output__.writeTag(1, 2)
        _output__.writeUInt32NoTag(__v.serializedSize)
        __v.writeTo(_output__)
      };
      downMachines.foreach { __v =>
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__v.serializedSize)
        __v.writeTo(_output__)
      };
    }
    def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): ClusterStatus = {
      val __drainingMachines = (_root_.scala.collection.immutable.Vector.newBuilder[ClusterStatus.DrainingMachine] ++= this.drainingMachines)
      val __downMachines = (_root_.scala.collection.immutable.Vector.newBuilder[org.apache.mesos.v1.mesos.MachineID] ++= this.downMachines)
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 10 =>
            __drainingMachines += _root_.com.trueaccord.scalapb.LiteParser.readMessage(_input__, maintenance.ClusterStatus.DrainingMachine.defaultInstance)
          case 18 =>
            __downMachines += _root_.com.trueaccord.scalapb.LiteParser.readMessage(_input__, org.apache.mesos.v1.mesos.MachineID.defaultInstance)
          case tag => _input__.skipField(tag)
        }
      }
      maintenance.ClusterStatus(
          drainingMachines = __drainingMachines.result(),
          downMachines = __downMachines.result()
      )
    }
    def clearDrainingMachines = copy(drainingMachines = _root_.scala.collection.Seq.empty)
    def addDrainingMachines(__vs: ClusterStatus.DrainingMachine*): ClusterStatus = addAllDrainingMachines(__vs)
    def addAllDrainingMachines(__vs: TraversableOnce[ClusterStatus.DrainingMachine]): ClusterStatus = copy(drainingMachines = drainingMachines ++ __vs)
    def withDrainingMachines(__v: _root_.scala.collection.Seq[ClusterStatus.DrainingMachine]): ClusterStatus = copy(drainingMachines = __v)
    def clearDownMachines = copy(downMachines = _root_.scala.collection.Seq.empty)
    def addDownMachines(__vs: org.apache.mesos.v1.mesos.MachineID*): ClusterStatus = addAllDownMachines(__vs)
    def addAllDownMachines(__vs: TraversableOnce[org.apache.mesos.v1.mesos.MachineID]): ClusterStatus = copy(downMachines = downMachines ++ __vs)
    def withDownMachines(__v: _root_.scala.collection.Seq[org.apache.mesos.v1.mesos.MachineID]): ClusterStatus = copy(downMachines = __v)
    def getFieldByNumber(__fieldNumber: Int): scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => drainingMachines
        case 2 => downMachines
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PRepeated(drainingMachines.map(_.toPMessage)(_root_.scala.collection.breakOut))
        case 2 => _root_.scalapb.descriptors.PRepeated(downMachines.map(_.toPMessage)(_root_.scala.collection.breakOut))
      }
    }
    override def toString: String = _root_.com.trueaccord.scalapb.TextFormat.printToUnicodeString(this)
    def companion = maintenance.ClusterStatus
}

object ClusterStatus extends com.trueaccord.scalapb.GeneratedMessageCompanion[ClusterStatus] {
  implicit def messageCompanion: com.trueaccord.scalapb.GeneratedMessageCompanion[ClusterStatus] = this
  def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, scala.Any]): ClusterStatus = {
    require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
    val __fields = javaDescriptor.getFields
    maintenance.ClusterStatus(
      __fieldsMap.getOrElse(__fields.get(0), Nil).asInstanceOf[_root_.scala.collection.Seq[ClusterStatus.DrainingMachine]],
      __fieldsMap.getOrElse(__fields.get(1), Nil).asInstanceOf[_root_.scala.collection.Seq[org.apache.mesos.v1.mesos.MachineID]]
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[ClusterStatus] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
      maintenance.ClusterStatus(
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.collection.Seq[ClusterStatus.DrainingMachine]]).getOrElse(_root_.scala.collection.Seq.empty),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.collection.Seq[org.apache.mesos.v1.mesos.MachineID]]).getOrElse(_root_.scala.collection.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = MaintenanceProto.javaDescriptor.getMessageTypes.get(2)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = MaintenanceProto.scalaDescriptor.messages(2)
  def messageCompanionForFieldNumber(__fieldNumber: Int): _root_.com.trueaccord.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.com.trueaccord.scalapb.GeneratedMessageCompanion[_] = null
    (__fieldNumber: @_root_.scala.unchecked) match {
      case 1 => __out = maintenance.ClusterStatus.DrainingMachine
      case 2 => __out = org.apache.mesos.v1.mesos.MachineID
    }
    __out
  }
  def enumCompanionForFieldNumber(__fieldNumber: Int): _root_.com.trueaccord.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = maintenance.ClusterStatus(
  )
  /** @param statuses
    *   A list of the most recent responses to inverse offers from frameworks
    *   running on this draining machine.
    */
  @SerialVersionUID(0L)
  final case class DrainingMachine(
      id: org.apache.mesos.v1.mesos.MachineID,
      statuses: _root_.scala.collection.Seq[InverseOfferStatus] = _root_.scala.collection.Seq.empty
      ) extends com.trueaccord.scalapb.GeneratedMessage with com.trueaccord.scalapb.Message[DrainingMachine] with com.trueaccord.lenses.Updatable[DrainingMachine] {
      @transient
      private[this] var __serializedSizeCachedValue: Int = 0
      private[this] def __computeSerializedValue(): Int = {
        var __size = 0
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(id.serializedSize) + id.serializedSize
        statuses.foreach(statuses => __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(statuses.serializedSize) + statuses.serializedSize)
        __size
      }
      final override def serializedSize: Int = {
        var read = __serializedSizeCachedValue
        if (read == 0) {
          read = __computeSerializedValue()
          __serializedSizeCachedValue = read
        }
        read
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): Unit = {
        _output__.writeTag(1, 2)
        _output__.writeUInt32NoTag(id.serializedSize)
        id.writeTo(_output__)
        statuses.foreach { __v =>
          _output__.writeTag(2, 2)
          _output__.writeUInt32NoTag(__v.serializedSize)
          __v.writeTo(_output__)
        };
      }
      def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): ClusterStatus.DrainingMachine = {
        var __id = this.id
        val __statuses = (_root_.scala.collection.immutable.Vector.newBuilder[InverseOfferStatus] ++= this.statuses)
        var __requiredFields0: Long = 0x1L
        var _done__ = false
        while (!_done__) {
          val _tag__ = _input__.readTag()
          _tag__ match {
            case 0 => _done__ = true
            case 10 =>
              __id = _root_.com.trueaccord.scalapb.LiteParser.readMessage(_input__, __id)
              __requiredFields0 &= 0xfffffffffffffffeL
            case 18 =>
              __statuses += _root_.com.trueaccord.scalapb.LiteParser.readMessage(_input__, allocator.InverseOfferStatus.defaultInstance)
            case tag => _input__.skipField(tag)
          }
        }
        if (__requiredFields0 != 0L) { throw new _root_.com.google.protobuf.InvalidProtocolBufferException("Message missing required fields.") } 
        maintenance.ClusterStatus.DrainingMachine(
            id = __id,
            statuses = __statuses.result()
        )
      }
      def withId(__v: org.apache.mesos.v1.mesos.MachineID): DrainingMachine = copy(id = __v)
      def clearStatuses = copy(statuses = _root_.scala.collection.Seq.empty)
      def addStatuses(__vs: InverseOfferStatus*): DrainingMachine = addAllStatuses(__vs)
      def addAllStatuses(__vs: TraversableOnce[InverseOfferStatus]): DrainingMachine = copy(statuses = statuses ++ __vs)
      def withStatuses(__v: _root_.scala.collection.Seq[InverseOfferStatus]): DrainingMachine = copy(statuses = __v)
      def getFieldByNumber(__fieldNumber: Int): scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => id
          case 2 => statuses
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => id.toPMessage
          case 2 => _root_.scalapb.descriptors.PRepeated(statuses.map(_.toPMessage)(_root_.scala.collection.breakOut))
        }
      }
      override def toString: String = _root_.com.trueaccord.scalapb.TextFormat.printToUnicodeString(this)
      def companion = maintenance.ClusterStatus.DrainingMachine
  }
  
  object DrainingMachine extends com.trueaccord.scalapb.GeneratedMessageCompanion[ClusterStatus.DrainingMachine] {
    implicit def messageCompanion: com.trueaccord.scalapb.GeneratedMessageCompanion[ClusterStatus.DrainingMachine] = this
    def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, scala.Any]): ClusterStatus.DrainingMachine = {
      require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
      val __fields = javaDescriptor.getFields
      maintenance.ClusterStatus.DrainingMachine(
        __fieldsMap(__fields.get(0)).asInstanceOf[org.apache.mesos.v1.mesos.MachineID],
        __fieldsMap.getOrElse(__fields.get(1), Nil).asInstanceOf[_root_.scala.collection.Seq[InverseOfferStatus]]
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[ClusterStatus.DrainingMachine] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
        maintenance.ClusterStatus.DrainingMachine(
          __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).get.as[org.apache.mesos.v1.mesos.MachineID],
          __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.collection.Seq[InverseOfferStatus]]).getOrElse(_root_.scala.collection.Seq.empty)
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = maintenance.ClusterStatus.javaDescriptor.getNestedTypes.get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = maintenance.ClusterStatus.scalaDescriptor.nestedMessages(0)
    def messageCompanionForFieldNumber(__fieldNumber: Int): _root_.com.trueaccord.scalapb.GeneratedMessageCompanion[_] = {
      var __out: _root_.com.trueaccord.scalapb.GeneratedMessageCompanion[_] = null
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => __out = org.apache.mesos.v1.mesos.MachineID
        case 2 => __out = allocator.InverseOfferStatus
      }
      __out
    }
    def enumCompanionForFieldNumber(__fieldNumber: Int): _root_.com.trueaccord.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = maintenance.ClusterStatus.DrainingMachine(
      id = org.apache.mesos.v1.mesos.MachineID.defaultInstance
    )
    implicit class DrainingMachineLens[UpperPB](_l: _root_.com.trueaccord.lenses.Lens[UpperPB, ClusterStatus.DrainingMachine]) extends _root_.com.trueaccord.lenses.ObjectLens[UpperPB, ClusterStatus.DrainingMachine](_l) {
      def id: _root_.com.trueaccord.lenses.Lens[UpperPB, org.apache.mesos.v1.mesos.MachineID] = field(_.id)((c_, f_) => c_.copy(id = f_))
      def statuses: _root_.com.trueaccord.lenses.Lens[UpperPB, _root_.scala.collection.Seq[InverseOfferStatus]] = field(_.statuses)((c_, f_) => c_.copy(statuses = f_))
    }
    final val ID_FIELD_NUMBER = 1
    final val STATUSES_FIELD_NUMBER = 2
  }
  
  implicit class ClusterStatusLens[UpperPB](_l: _root_.com.trueaccord.lenses.Lens[UpperPB, ClusterStatus]) extends _root_.com.trueaccord.lenses.ObjectLens[UpperPB, ClusterStatus](_l) {
    def drainingMachines: _root_.com.trueaccord.lenses.Lens[UpperPB, _root_.scala.collection.Seq[ClusterStatus.DrainingMachine]] = field(_.drainingMachines)((c_, f_) => c_.copy(drainingMachines = f_))
    def downMachines: _root_.com.trueaccord.lenses.Lens[UpperPB, _root_.scala.collection.Seq[org.apache.mesos.v1.mesos.MachineID]] = field(_.downMachines)((c_, f_) => c_.copy(downMachines = f_))
  }
  final val DRAINING_MACHINES_FIELD_NUMBER = 1
  final val DOWN_MACHINES_FIELD_NUMBER = 2
}
